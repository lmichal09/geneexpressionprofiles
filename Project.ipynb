{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298a9e15-6d28-4a7e-8e8e-11794524a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install umap-learn\n",
    "#!pip3 install leidenalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5aa58c9-5b7b-48e3-9bd7-ed7580f4ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import umap.umap_ as umap\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331d41f2-44d1-4dc7-900f-e5c28103cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess_data(data, dataset_name):\n",
    "    print(f\"Preprocessing {dataset_name} data...\")\n",
    "    # Log transformation to reduce skewness (add small constant to avoid log(0))\n",
    "    log_data = np.log1p(data)\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    preprocessed_data = scaler.fit_transform(log_data)\n",
    "    # Filter low variance genes\n",
    "    print(f\"Filtering low variance genes for {dataset_name}...\")\n",
    "    variance_threshold = 0.1\n",
    "    variances = np.var(preprocessed_data, axis=0)\n",
    "    high_var_indices = np.where(variances > variance_threshold)[0]\n",
    "    preprocessed_data = preprocessed_data[:, high_var_indices]\n",
    "    print(f\"{dataset_name} data shape after filtering: {preprocessed_data.shape}\")\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5c987a-afc5-414b-a860-ae67c8a6b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dimensionality reduction\n",
    "def apply_dim_reduction(preprocessed_data, labels, dataset_name):\n",
    "    print(f\"Applying dimensionality reduction for {dataset_name}...\")\n",
    "\n",
    "    # Apply PCA\n",
    "    print(\"Applying PCA...\")\n",
    "    n_components = min(50, preprocessed_data.shape[1], preprocessed_data.shape[0])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_data = pca.fit_transform(preprocessed_data)\n",
    "    print(f\"PCA data shape: {pca_data.shape}\")\n",
    "\n",
    "    # Explained variance\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    cumulative_var = np.cumsum(explained_var)\n",
    "    print(f\"Explained variance by first 10 components: {explained_var[:10]}\")\n",
    "    print(f\"Cumulative explained variance by first 10 components: {cumulative_var[:10]}\")\n",
    "\n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(1, len(explained_var) + 1), explained_var, alpha=0.5, align='center')\n",
    "    plt.step(range(1, len(cumulative_var) + 1), cumulative_var, where='mid')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.title(f'Explained Variance by Principal Components - {dataset_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'pca_explained_variance_{dataset_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Apply t-SNE\n",
    "    print(\"Applying t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=min(30, preprocessed_data.shape[0] - 1), random_state=42)\n",
    "    tsne_data = tsne.fit_transform(preprocessed_data)\n",
    "    print(f\"t-SNE data shape: {tsne_data.shape}\")\n",
    "\n",
    "    # Apply UMAP\n",
    "    print(\"Applying UMAP...\")\n",
    "    n_neighbors = min(15, preprocessed_data.shape[0] - 1)\n",
    "    reducer = umap.UMAP(n_components=2, n_neighbors=n_neighbors, min_dist=0.1, random_state=42)\n",
    "    umap_data = reducer.fit_transform(preprocessed_data)\n",
    "    print(f\"UMAP data shape: {umap_data.shape}\")\n",
    "\n",
    "    # Store reduced data in a dictionary for easy access\n",
    "    reduced_data = {\n",
    "        'pca': pca_data,\n",
    "        'tsne': tsne_data,\n",
    "        'umap': umap_data\n",
    "    }\n",
    "\n",
    "    # Visualize dimensionality reduction results with labels\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Set color palette for the number of unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_labels = len(unique_labels)\n",
    "    color_palette = sns.color_palette(\"hls\", n_labels)\n",
    "    label_color_map = {label: color_palette[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # PCA Plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for label in unique_labels:\n",
    "        idx = labels == label\n",
    "        plt.scatter(pca_data[idx, 0], pca_data[idx, 1], c=[label_color_map[label]], label=f'Class {label}', alpha=0.7)\n",
    "    plt.title(f'PCA Projection - {dataset_name}')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.legend()\n",
    "\n",
    "    # t-SNE Plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for label in unique_labels:\n",
    "        idx = labels == label\n",
    "        plt.scatter(tsne_data[idx, 0], tsne_data[idx, 1], c=[label_color_map[label]], label=f'Class {label}', alpha=0.7)\n",
    "    plt.title(f't-SNE Projection - {dataset_name}')\n",
    "    plt.xlabel('t-SNE1')\n",
    "    plt.ylabel('t-SNE2')\n",
    "    plt.legend()\n",
    "\n",
    "    # UMAP Plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for label in unique_labels:\n",
    "        idx = labels == label\n",
    "        plt.scatter(umap_data[idx, 0], umap_data[idx, 1], c=[label_color_map[label]], label=f'Class {label}', alpha=0.7)\n",
    "    plt.title(f'UMAP Projection - {dataset_name}')\n",
    "    plt.xlabel('UMAP1')\n",
    "    plt.ylabel('UMAP2')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'dimensionality_reduction_comparison_{dataset_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c59581a-ae92-4611-a636-272e70bba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering\n",
    "def apply_kmeans(reduced_data, labels, dataset_name):\n",
    "    print(f\"Applying K-means clustering for {dataset_name}...\")\n",
    "    dim_reduction_methods = list(reduced_data.keys())\n",
    "    k_range = range(2, min(11, reduced_data['pca'].shape[0]))\n",
    "    kmeans_results = {}\n",
    "\n",
    "    for method in dim_reduction_methods:\n",
    "        # Calculate inertia and silhouette scores for different k values\n",
    "        inertia = []\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(reduced_data[method])\n",
    "            inertia.append(kmeans.inertia_)\n",
    "\n",
    "            # Calculate silhouette score if k > 1\n",
    "            if k > 1:\n",
    "                silhouette_scores.append(silhouette_score(reduced_data[method], cluster_labels))\n",
    "            else:\n",
    "                silhouette_scores.append(0)  # Silhouette score not defined for k=1\n",
    "\n",
    "        # Find optimal k using silhouette score\n",
    "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "        # Rerun K-means with optimal k\n",
    "        optimal_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        cluster_labels = optimal_kmeans.fit_predict(reduced_data[method])\n",
    "\n",
    "        # Store results\n",
    "        kmeans_results[method] = {\n",
    "            'labels': cluster_labels,\n",
    "            'optimal_k': optimal_k,\n",
    "            'inertia': inertia,\n",
    "            'silhouette_scores': silhouette_scores\n",
    "        }\n",
    "\n",
    "        print(f\"K-means on {method} {dataset_name} data: Optimal k = {optimal_k}, Silhouette Score = {silhouette_scores[optimal_k-2]:.4f}\")\n",
    "\n",
    "        # Calculate Adjusted Rand Index if true labels are available\n",
    "        ari = adjusted_rand_score(labels, cluster_labels)\n",
    "        print(f\"K-means on {method} {dataset_name} data: Adjusted Rand Index = {ari:.4f}\")\n",
    "\n",
    "        # Plot K-means results\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Plot elbow curve\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(k_range, inertia, 'o-')\n",
    "        plt.xlabel('Number of clusters (k)')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Elbow Method for Optimal k')\n",
    "        plt.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "\n",
    "        # Plot silhouette scores\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(k_range, silhouette_scores, 'o-')\n",
    "        plt.xlabel('Number of clusters (k)')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Scores for Different k')\n",
    "        plt.axvline(x=optimal_k, color='r', linestyle='--')\n",
    "\n",
    "        # Plot clustering results\n",
    "        plt.subplot(1, 3, 3)\n",
    "        scatter = plt.scatter(reduced_data[method][:, 0], reduced_data[method][:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.title(f'K-means Clustering on {method.upper()} (k={optimal_k})')\n",
    "        plt.xlabel(f'{method.upper()}1')\n",
    "        plt.ylabel(f'{method.upper()}2')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'kmeans_{method}_results_{dataset_name.lower()}.png')\n",
    "        plt.close()\n",
    "\n",
    "    return kmeans_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f70239-d796-4576-adcb-dc8beb86d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hierarchical clustering\n",
    "def apply_hierarchical(reduced_data, labels, dataset_name):\n",
    "    print(f\"Applying hierarchical clustering for {dataset_name}...\")\n",
    "    dim_reduction_methods = list(reduced_data.keys())\n",
    "    k_range = range(2, min(11, reduced_data['pca'].shape[0]))\n",
    "    hierarchical_results = {}\n",
    "\n",
    "    for method in dim_reduction_methods:\n",
    "        # Calculate linkage matrix for dendrogram\n",
    "        Z = linkage(reduced_data[method], method='ward')\n",
    "\n",
    "        # Calculate silhouette scores for different numbers of clusters\n",
    "        silhouette_scores = []\n",
    "\n",
    "        for k in k_range:\n",
    "            hc = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "            cluster_labels = hc.fit_predict(reduced_data[method])\n",
    "\n",
    "            # Calculate silhouette score if k > 1\n",
    "            if k > 1:\n",
    "                silhouette_scores.append(silhouette_score(reduced_data[method], cluster_labels))\n",
    "            else:\n",
    "                silhouette_scores.append(0)  # Silhouette score not defined for k=1\n",
    "\n",
    "        # Find optimal k using silhouette score\n",
    "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "        # Rerun hierarchical clustering with optimal k\n",
    "        optimal_hc = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
    "        cluster_labels = optimal_hc.fit_predict(reduced_data[method])\n",
    "\n",
    "        # Store results\n",
    "        hierarchical_results[method] = {\n",
    "            'labels': cluster_labels,\n",
    "            'optimal_k': optimal_k,\n",
    "            'linkage': Z,\n",
    "            'silhouette_scores': silhouette_scores\n",
    "        }\n",
    "\n",
    "        print(f\"Hierarchical on {method} {dataset_name} data: Optimal k = {optimal_k}, Silhouette Score = {silhouette_scores[optimal_k-2]:.4f}\")\n",
    "\n",
    "        # Calculate Adjusted Rand Index if true labels are available\n",
    "        ari = adjusted_rand_score(labels, cluster_labels)\n",
    "        print(f\"Hierarchical on {method} {dataset_name} data: Adjusted Rand Index = {ari:.4f}\")\n",
    "\n",
    "        # Plot dendrogram\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        dendrogram(Z, leaf_rotation=90., leaf_font_size=10., color_threshold=None, truncate_mode='lastp', p=30)\n",
    "        plt.title(f'Hierarchical Clustering Dendrogram ({method.upper()} - {dataset_name})')\n",
    "        plt.xlabel('Sample index')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.axhline(y=Z[-optimal_k+1, 2], c='k', ls='--', lw=1)  # Add line at cut height for optimal k\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'hierarchical_{method}_dendrogram_{dataset_name.lower()}.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot clustering results\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(reduced_data[method][:, 0], reduced_data[method][:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.title(f'Hierarchical Clustering on {method.upper()} (k={optimal_k} - {dataset_name})')\n",
    "        plt.xlabel(f'{method.upper()}1')\n",
    "        plt.ylabel(f'{method.upper()}2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'hierarchical_{method}_clusters_{dataset_name.lower()}.png')\n",
    "        plt.close()\n",
    "\n",
    "    return hierarchical_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5ddc60-0bca-416f-b56a-8ed960cd7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Leiden clustering\n",
    "def apply_leiden(reduced_data, labels, dataset_name):\n",
    "    print(f\"Applying Leiden clustering for {dataset_name} dataset...\")\n",
    "    dim_reduction_methods = list(reduced_data.keys())\n",
    "    resolution_range = np.arange(0.1, 2.1, 0.1)\n",
    "    leiden_results = {}\n",
    "\n",
    "    for method in dim_reduction_methods:\n",
    "        # Set k nearest neighbors parameter\n",
    "        k_nearest_neighbors = min(15, reduced_data[method].shape[0] - 1)\n",
    "\n",
    "        # Compute distance matrix\n",
    "        dist_matrix = squareform(pdist(reduced_data[method], metric='euclidean'))\n",
    "\n",
    "        # Create KNN graph\n",
    "        knn_graph = np.zeros((reduced_data[method].shape[0], reduced_data[method].shape[0]))\n",
    "        for i in range(reduced_data[method].shape[0]):\n",
    "            # Find k nearest neighbors for each sample\n",
    "            indices = np.argsort(dist_matrix[i])[1:k_nearest_neighbors+1]  # exclude self\n",
    "            knn_graph[i, indices] = 1\n",
    "\n",
    "        # Make the graph symmetric\n",
    "        knn_graph = np.maximum(knn_graph, knn_graph.T)\n",
    "\n",
    "        # Convert to igraph\n",
    "        g = ig.Graph.Adjacency((knn_graph > 0).tolist(), mode='undirected')\n",
    "\n",
    "        # Evaluate different resolutions\n",
    "        silhouette_scores = []\n",
    "        cluster_labels_list = []\n",
    "\n",
    "        for resolution in resolution_range:\n",
    "            # Apply Leiden algorithm\n",
    "            partition = leidenalg.find_partition(g, leidenalg.RBConfigurationVertexPartition,\n",
    "                                                resolution_parameter=resolution)\n",
    "\n",
    "            cluster_labels = np.array(partition.membership)\n",
    "            cluster_labels_list.append(cluster_labels)\n",
    "\n",
    "            # Calculate silhouette score if more than one cluster\n",
    "            n_clusters = len(set(cluster_labels))\n",
    "            if n_clusters > 1:\n",
    "                silhouette_scores.append(silhouette_score(reduced_data[method], cluster_labels))\n",
    "            else:\n",
    "                silhouette_scores.append(0)  # Silhouette score not defined for k=1\n",
    "\n",
    "        # Find optimal resolution parameter\n",
    "        optimal_idx = np.argmax(silhouette_scores)\n",
    "        optimal_resolution = resolution_range[optimal_idx]\n",
    "        optimal_cluster_labels = cluster_labels_list[optimal_idx]\n",
    "        optimal_n_clusters = len(set(optimal_cluster_labels))\n",
    "\n",
    "        # Store clustering results\n",
    "        leiden_results[method] = {\n",
    "            'labels': optimal_cluster_labels,\n",
    "            'optimal_resolution': optimal_resolution,\n",
    "            'silhouette_scores': silhouette_scores,\n",
    "            'n_clusters': optimal_n_clusters\n",
    "        }\n",
    "\n",
    "        print(f\"Leiden on {method} data ({dataset_name}): Optimal resolution = {optimal_resolution:.1f}, \"\n",
    "              f\"Number of clusters = {optimal_n_clusters}, \"\n",
    "              f\"Silhouette Score = {silhouette_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "        # Calculate Adjusted Rand Index if true labels are available\n",
    "        ari = adjusted_rand_score(labels, optimal_cluster_labels)\n",
    "        print(f\"Leiden on {method} data ({dataset_name}): Adjusted Rand Index = {ari:.4f}\")\n",
    "\n",
    "        # Plot Leiden results\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Plot silhouette scores for different resolutions\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(resolution_range, silhouette_scores, 'o-')\n",
    "        plt.xlabel('Resolution Parameter')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Scores for Different Resolutions')\n",
    "        plt.axvline(x=optimal_resolution, color='r', linestyle='--')\n",
    "\n",
    "        # Plot number of clusters for different resolutions\n",
    "        plt.subplot(1, 3, 2)\n",
    "        n_clusters_list = [len(set(labels)) for labels in cluster_labels_list]\n",
    "        plt.plot(resolution_range, n_clusters_list, 'o-')\n",
    "        plt.xlabel('Resolution Parameter')\n",
    "        plt.ylabel('Number of Clusters')\n",
    "        plt.title('Number of Clusters for Different Resolutions')\n",
    "        plt.axvline(x=optimal_resolution, color='r', linestyle='--')\n",
    "\n",
    "        # Plot clustering results\n",
    "        plt.subplot(1, 3, 3)\n",
    "        scatter = plt.scatter(reduced_data[method][:, 0], reduced_data[method][:, 1],\n",
    "                            c=optimal_cluster_labels, cmap='viridis', s=50, alpha=0.7)\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.title(f'Leiden Clustering on {method.upper()} (res={optimal_resolution:.1f}, k={optimal_n_clusters})')\n",
    "        plt.xlabel(f'{method.upper()}1')\n",
    "        plt.ylabel(f'{method.upper()}2')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'leiden_{method}_results_{dataset_name.lower()}.png')\n",
    "        plt.close()\n",
    "\n",
    "    return leiden_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb549945-acbd-4855-98b4-4478a7d76e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jaccard Index\n",
    "def jaccard_index(labels_true, labels_pred):\n",
    "    n = len(labels_true)\n",
    "    pairs_true = set()\n",
    "    pairs_pred = set()\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if labels_true[i] == labels_true[j]:\n",
    "                pairs_true.add((i, j))\n",
    "            if labels_pred[i] == labels_pred[j]:\n",
    "                pairs_pred.add((i, j))\n",
    "\n",
    "    intersection = pairs_true.intersection(pairs_pred)\n",
    "    union = pairs_true.union(pairs_pred)\n",
    "\n",
    "    if len(union) == 0:\n",
    "        return 0\n",
    "\n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f48f33-90c3-4383-9ac4-96f3a8236b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "def compare_methods(kmeans_results, hierarchical_results, leiden_results, labels, dataset_name):\n",
    "    print(f\"Comparing all clustering methods for {dataset_name}...\")\n",
    "    comparison_results = []\n",
    "    dim_reduction_methods = list(kmeans_results.keys())\n",
    "\n",
    "    for method in dim_reduction_methods:\n",
    "        kmeans_labels = kmeans_results[method]['labels']\n",
    "        hierarchical_labels = hierarchical_results[method]['labels']\n",
    "        leiden_labels = leiden_results[method]['labels']\n",
    "\n",
    "        kmeans_ari = adjusted_rand_score(labels, kmeans_labels)\n",
    "        hierarchical_ari = adjusted_rand_score(labels, hierarchical_labels)\n",
    "        leiden_ari = adjusted_rand_score(labels, leiden_labels)\n",
    "\n",
    "        kmeans_ji = jaccard_index(labels, kmeans_labels)\n",
    "        hierarchical_ji = jaccard_index(labels, hierarchical_labels)\n",
    "        leiden_ji = jaccard_index(labels, leiden_labels)\n",
    "\n",
    "        comparison_results.append({\n",
    "            'Dim Reduction': method.upper(),\n",
    "            'Method': 'K-means',\n",
    "            'Clusters': kmeans_results[method]['optimal_k'],\n",
    "            'ARI': kmeans_ari,\n",
    "            'Jaccard': kmeans_ji,\n",
    "            'Silhouette': max(kmeans_results[method]['silhouette_scores'])\n",
    "        })\n",
    "\n",
    "        comparison_results.append({\n",
    "            'Dim Reduction': method.upper(),\n",
    "            'Method': 'Hierarchical',\n",
    "            'Clusters': hierarchical_results[method]['optimal_k'],\n",
    "            'ARI': hierarchical_ari,\n",
    "            'Jaccard': hierarchical_ji,\n",
    "            'Silhouette': max(hierarchical_results[method]['silhouette_scores'])\n",
    "        })\n",
    "\n",
    "        comparison_results.append({\n",
    "            'Dim Reduction': method.upper(),\n",
    "            'Method': 'Leiden',\n",
    "            'Clusters': leiden_results[method]['n_clusters'],\n",
    "            'ARI': leiden_ari,\n",
    "            'Jaccard': leiden_ji,\n",
    "            'Silhouette': max(leiden_results[method]['silhouette_scores'])\n",
    "        })\n",
    "\n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    print(comparison_df)\n",
    "\n",
    "    # Save comparison results\n",
    "    comparison_df.to_csv(f'clustering_comparison_results_{dataset_name.lower()}.csv', index=False)\n",
    "\n",
    "    # Create heatmaps of comparison results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    heatmap_data = comparison_df.pivot_table(\n",
    "        index='Method',\n",
    "        columns='Dim Reduction',\n",
    "        values='ARI'\n",
    "    )\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f')\n",
    "    plt.title(f'Adjusted Rand Index Comparison - {dataset_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'ari_comparison_heatmap_{dataset_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Create a heatmap for Jaccard Index\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    heatmap_data = comparison_df.pivot_table(\n",
    "        index='Method',\n",
    "        columns='Dim Reduction',\n",
    "        values='Jaccard'\n",
    "    )\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f')\n",
    "    plt.title(f'Jaccard Index Comparison - {dataset_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'jaccard_comparison_heatmap_{dataset_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Create a heatmap for Silhouette Score\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    heatmap_data = comparison_df.pivot_table(\n",
    "        index='Method',\n",
    "        columns='Dim Reduction',\n",
    "        values='Silhouette'\n",
    "    )\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f')\n",
    "    plt.title(f'Silhouette Score Comparison - {dataset_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'silhouette_comparison_heatmap_{dataset_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b22a4a-fa86-4106-b039-d7780d82e89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Loading Arcene dataset...\")\\narcene_train_path = r\"/Users/leilamichal/Desktop/Genomics/Project/arcene/ARCENE/arcene_train.data\"\\narcene_labels_path = r\"/Users/leilamichal/Desktop/Genomics/Project/arcene/ARCENE/arcene_train.labels\"\\ndata_arcene = pd.read_csv(arcene_train_path, delim_whitespace=True, header=None)\\nlabels_arcene = pd.read_csv(arcene_labels_path, delim_whitespace=True, header=None)[0].values\\nprint(\"Arcene Train Shape:\", data_arcene.shape)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Arcene dataset\n",
    "'''\n",
    "print(\"Loading Arcene dataset...\")\n",
    "arcene_train_path = r\"/Users/leilamichal/Desktop/Genomics/Project/arcene/ARCENE/arcene_train.data\"\n",
    "arcene_labels_path = r\"/Users/leilamichal/Desktop/Genomics/Project/arcene/ARCENE/arcene_train.labels\"\n",
    "data_arcene = pd.read_csv(arcene_train_path, delim_whitespace=True, header=None)\n",
    "labels_arcene = pd.read_csv(arcene_labels_path, delim_whitespace=True, header=None)[0].values\n",
    "print(\"Arcene Train Shape:\", data_arcene.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28540c80-ffed-44b2-a733-122abcfd0d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\n====== PROCESSING ARCENE DATASET ======\\n\")\\npreprocessed_arcene = preprocess_data(data_arcene, \"Arcene\")\\nreduced_data_arcene = apply_dim_reduction(preprocessed_arcene, labels_arcene, \"Arcene\")\\nkmeans_results_arcene = apply_kmeans(reduced_data_arcene, labels_arcene, \"Arcene\")\\nhierarchical_results_arcene = apply_hierarchical(reduced_data_arcene, labels_arcene, \"Arcene\")\\nleiden_results_arcene = apply_leiden(reduced_data_arcene, labels_arcene, \"Arcene\")\\ncomparison_arcene = compare_methods(kmeans_results_arcene, hierarchical_results_arcene, leiden_results_arcene, labels_arcene, \"Arcene\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process Arcene dataset\n",
    "'''\n",
    "print(\"\\n====== PROCESSING ARCENE DATASET ======\\n\")\n",
    "preprocessed_arcene = preprocess_data(data_arcene, \"Arcene\")\n",
    "reduced_data_arcene = apply_dim_reduction(preprocessed_arcene, labels_arcene, \"Arcene\")\n",
    "kmeans_results_arcene = apply_kmeans(reduced_data_arcene, labels_arcene, \"Arcene\")\n",
    "hierarchical_results_arcene = apply_hierarchical(reduced_data_arcene, labels_arcene, \"Arcene\")\n",
    "leiden_results_arcene = apply_leiden(reduced_data_arcene, labels_arcene, \"Arcene\")\n",
    "comparison_arcene = compare_methods(kmeans_results_arcene, hierarchical_results_arcene, leiden_results_arcene, labels_arcene, \"Arcene\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e053298f-8a8f-4d0a-b09c-c09155baf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gene Expression dataset...\n",
      "Gene Expression Data Shape: (801, 20531)\n"
     ]
    }
   ],
   "source": [
    "# Load Gene Expression dataset\n",
    "print(\"Loading Gene Expression dataset...\")\n",
    "gene_data_path = r\"/Users/leilamichal/Desktop/Genomics/Project/Gene Expression Cancer RNA-Seq/data.csv\"\n",
    "gene_labels_path = r\"/Users/leilamichal/Desktop/Genomics/Project/Gene Expression Cancer RNA-Seq/labels.csv\"\n",
    "gene_data = pd.read_csv(gene_data_path)\n",
    "gene_labels = pd.read_csv(gene_labels_path)\n",
    "data_gene_exp = gene_data.iloc[:, 1:]  # Skip first column if it's an ID\n",
    "labels_gene_exp = gene_labels[\"Class\"].values\n",
    "print(\"Gene Expression Data Shape:\", data_gene_exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a111640-6699-4986-862f-a12425b29b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== PROCESSING GENE EXPRESSION DATASET ======\n",
      "\n",
      "Preprocessing GeneExp data...\n",
      "Filtering low variance genes for GeneExp...\n",
      "GeneExp data shape after filtering: (801, 20264)\n",
      "Applying dimensionality reduction for GeneExp...\n",
      "Applying PCA...\n",
      "PCA data shape: (801, 50)\n",
      "Explained variance by first 10 components: [0.10444959 0.08560711 0.07638704 0.05198099 0.04065827 0.02890545\n",
      " 0.0223515  0.02086762 0.01626109 0.01196373]\n",
      "Cumulative explained variance by first 10 components: [0.10444959 0.1900567  0.26644374 0.31842473 0.35908301 0.38798845\n",
      " 0.41033995 0.43120757 0.44746866 0.45943239]\n",
      "Applying t-SNE...\n",
      "t-SNE data shape: (801, 2)\n",
      "Applying UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP data shape: (801, 2)\n",
      "Applying K-means clustering for GeneExp...\n",
      "K-means on pca GeneExp data: Optimal k = 7, Silhouette Score = 0.2462\n",
      "K-means on pca GeneExp data: Adjusted Rand Index = 0.7979\n",
      "K-means on tsne GeneExp data: Optimal k = 5, Silhouette Score = 0.7341\n",
      "K-means on tsne GeneExp data: Adjusted Rand Index = 0.9925\n",
      "K-means on umap GeneExp data: Optimal k = 5, Silhouette Score = 0.8891\n",
      "K-means on umap GeneExp data: Adjusted Rand Index = 0.9925\n",
      "Applying hierarchical clustering for GeneExp...\n",
      "Hierarchical on pca GeneExp data: Optimal k = 7, Silhouette Score = 0.2463\n",
      "Hierarchical on pca GeneExp data: Adjusted Rand Index = 0.8295\n",
      "Hierarchical on tsne GeneExp data: Optimal k = 5, Silhouette Score = 0.7341\n",
      "Hierarchical on tsne GeneExp data: Adjusted Rand Index = 0.9925\n",
      "Hierarchical on umap GeneExp data: Optimal k = 5, Silhouette Score = 0.8891\n",
      "Hierarchical on umap GeneExp data: Adjusted Rand Index = 0.9925\n",
      "Applying Leiden clustering for GeneExp dataset...\n",
      "Leiden on pca data (GeneExp): Optimal resolution = 0.5, Number of clusters = 6, Silhouette Score = 0.2395\n",
      "Leiden on pca data (GeneExp): Adjusted Rand Index = 0.8875\n",
      "Leiden on tsne data (GeneExp): Optimal resolution = 0.5, Number of clusters = 7, Silhouette Score = 0.6612\n",
      "Leiden on tsne data (GeneExp): Adjusted Rand Index = 0.7568\n",
      "Leiden on umap data (GeneExp): Optimal resolution = 0.2, Number of clusters = 7, Silhouette Score = 0.7667\n",
      "Leiden on umap data (GeneExp): Adjusted Rand Index = 0.7635\n",
      "Comparing all clustering methods for GeneExp...\n",
      "  Dim Reduction        Method  Clusters       ARI   Jaccard  Silhouette\n",
      "0           PCA       K-means         7  0.797902  0.724120    0.246198\n",
      "1           PCA  Hierarchical         7  0.829469  0.763170    0.246290\n",
      "2           PCA        Leiden         6  0.887511  0.839177    0.239471\n",
      "3          TSNE       K-means         5  0.992538  0.988756    0.734129\n",
      "4          TSNE  Hierarchical         5  0.992538  0.988756    0.734129\n",
      "5          TSNE        Leiden         7  0.756781  0.672646    0.661165\n",
      "6          UMAP       K-means         5  0.992538  0.988756    0.889073\n",
      "7          UMAP  Hierarchical         5  0.992538  0.988756    0.889073\n",
      "8          UMAP        Leiden         7  0.763490  0.680701    0.766656\n"
     ]
    }
   ],
   "source": [
    "# Process Gene Expression dataset\n",
    "print(\"\\n====== PROCESSING GENE EXPRESSION DATASET ======\\n\")\n",
    "preprocessed_gene_exp = preprocess_data(data_gene_exp, \"GeneExp\")\n",
    "reduced_data_gene_exp = apply_dim_reduction(preprocessed_gene_exp, labels_gene_exp, \"GeneExp\")\n",
    "kmeans_results_gene_exp = apply_kmeans(reduced_data_gene_exp, labels_gene_exp, \"GeneExp\")\n",
    "hierarchical_results_gene_exp = apply_hierarchical(reduced_data_gene_exp, labels_gene_exp, \"GeneExp\")\n",
    "leiden_results_gene_exp = apply_leiden(reduced_data_gene_exp, labels_gene_exp, \"GeneExp\")\n",
    "comparison_gene_exp = compare_methods(kmeans_results_gene_exp, hierarchical_results_gene_exp, leiden_results_gene_exp, labels_gene_exp, \"GeneExp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3207014e-4482-491d-960c-9e1b3241bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== ANALYSIS COMPLETE ======\n",
      "\n",
      "\n",
      "Results for Gene Expression dataset:\n",
      "  Dim Reduction        Method  Clusters       ARI   Jaccard  Silhouette\n",
      "0           PCA       K-means         7  0.797902  0.724120    0.246198\n",
      "1           PCA  Hierarchical         7  0.829469  0.763170    0.246290\n",
      "2           PCA        Leiden         6  0.887511  0.839177    0.239471\n",
      "3          TSNE       K-means         5  0.992538  0.988756    0.734129\n",
      "4          TSNE  Hierarchical         5  0.992538  0.988756    0.734129\n",
      "5          TSNE        Leiden         7  0.756781  0.672646    0.661165\n",
      "6          UMAP       K-means         5  0.992538  0.988756    0.889073\n",
      "7          UMAP  Hierarchical         5  0.992538  0.988756    0.889073\n",
      "8          UMAP        Leiden         7  0.763490  0.680701    0.766656\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n====== ANALYSIS COMPLETE ======\\n\")\n",
    "#print(\"Results for Arcene dataset:\")\n",
    "#print(comparison_arcene)\n",
    "print(\"\\nResults for Gene Expression dataset:\")\n",
    "print(comparison_gene_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d08667-ad6e-4861-bc53-2665a1411d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete! Results saved to CSV and visualizations saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    '''\n",
    "    \"arcene\": {\n",
    "        \"preprocessed\": preprocessed_arcene,\n",
    "        \"reduced_data\": reduced_data_arcene,\n",
    "        \"kmeans\": kmeans_results_arcene,\n",
    "        \"hierarchical\": hierarchical_results_arcene,\n",
    "        \"leiden\": leiden_results_arcene,\n",
    "        \"comparison\": comparison_arcene\n",
    "    },\n",
    "    '''\n",
    "    \"gene_exp\": {\n",
    "        \"preprocessed\": preprocessed_gene_exp,\n",
    "        \"reduced_data\": reduced_data_gene_exp,\n",
    "        \"kmeans\": kmeans_results_gene_exp,\n",
    "        \"hierarchical\": hierarchical_results_gene_exp,\n",
    "        \"leiden\": leiden_results_gene_exp,\n",
    "        \"comparison\": comparison_gene_exp\n",
    "    }\n",
    "}\n",
    "print(\"Analysis complete! Results saved to CSV and visualizations saved as PNG files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
